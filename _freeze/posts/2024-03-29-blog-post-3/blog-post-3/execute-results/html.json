{
  "hash": "2578b94db4454fb9c6ce869768860eb0",
  "result": {
    "markdown": "---\ntitle: \"Blog Post 3\"\nauthor: \"\"\ndate: \"2024-03-29\"\ndate-modified: \"2024-03-29\"\ndraft: FALSE\n---\n\n**Data for Equity**\n\nPrinciple 1: One of the important principles in the process of data processing analysis is to be transparent about the limits of the data. While we are examining and cleaning the data, we noticed that there are many limitations with our data set in the research of US Police Involved Fatalities. Specifically, our data is effective while we are trying to examine the relationship between the police involvement and the fatalities of citizens. However, the data is definitely time-sensitive and our finding through this data set may not imply the Police involved fatalities in the past years. Besides, there is also missing data like whether the suspect is armed. If ARMED shows as blank then there is no record of whether the suspect is armed or not, which may play an important role in our data analysis and our result.\n\n\nPrinciple 2: For the beneficence principle regarding our dataset, it contains only the name of each police fatalities with no other sensitive information displayed. This could ensure the privacy of the person as well as their families. All other columns of the dataset are only served for the purpose of analyzing without disclosing much information about a single person. The dataset also contains a column called “uid” that can be uniquely identified across the dataset and can be used to substitute the function of names in certain occasions. \n\nPrinciple 3: another important principle is the Inclusivity of the data in representation. We use this principle to emphasize the importance of representing all affected communities fairly and accurately in the dataset. In the US Police Fatalities dataset, it literally means all the data reflected the demographic characteristics of those killed by police deaths, including race, age, gender, and mental health status. It can be essential in that it is an effective way to gain an insight into potential biases or differences in the ways diverse social groups may be affected by police action. \n\nPrinciple 4: We also need to mention accountability when we use data in real world practice. In the practice of data, we need to address any harm that the dataset and its analysis may cause, particularly to the minority communities. In the dataset US Police Fatalities, there's a significant risk that improper interpretation of the data could underscore the stereotypes or contribute to unjust narratives about certain groups.\n\n**Weekly Summary:**\n\nWe finished the Data Equity part. \n\nWe thought about 3-4 principles and how they could be relevant to our US Police Fatalities dataset. These principles help our data set to be used ethically and constructively.\n\nThe main aspect of our data principles is the potential for abuse or misuse based on the potential biased narratives in our dataset.\n\nWe started to do some data exploration with plots and tables. It might be interesting if we combined our dataset with another containing more population information for the states. We have a homicide dataset that we might want to add to our police fatality dataset. We also thought about how to construct our data plan and what questions we want to ask of our dataset.\n\n**Exploration**\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nprc <- read_csv(\"/Users/ccbeigh/Desktop/Data Science in R/final-project-team2/dataset/police_fatalities.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12491 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Name, Gender, Race, Date, City, State, Manner_of_death, Armed\ndbl (2): UID, Age\nlgl (2): Mental_illness, Flee\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nprc |> \n  na.omit() |>  \n  ggplot(aes(x = Race, fill = Gender)) + \n  geom_bar()\n```\n\n::: {.cell-output-display}\n![](blog-post-3_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nprc |> na.omit() |> group_by(State) |> summarize(n = n()) |> arrange(-n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 51 × 2\n   State     n\n   <chr> <int>\n 1 CA      966\n 2 TX      494\n 3 FL      310\n 4 AZ      194\n 5 NV      153\n 6 NY      137\n 7 WA      137\n 8 CO      125\n 9 OH      123\n10 IL      121\n# ℹ 41 more rows\n```\n:::\n:::\n\n\n\nBelow is a plot displaying the average age of police fatalities each year, separated by race.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsuppressWarnings({\nlibrary(tidyverse)\nlibrary(lubridate)\n\npolice_data_clean <- read_csv(here::here(\"dataset\", \"police_fatalities.csv\"))\n\npolice_fatalities_summary <- police_data_clean %>%\n  mutate(Date = dmy(Date),  \n         Year = year(Date)) %>%  \n  group_by(Year, Race) %>% \n  summarise(average_age = mean(Age, na.rm = TRUE)) \n\npolice_fatalities_summary %>%\n  ggplot(aes(x = Year, y = average_age, color = Race)) +\n  geom_line() +  \n  geom_point() + \n  labs(\n    title = \"Average Age of Police Fatalities by Year and Race\",\n    x = \"Year\",\n    y = \"Average Age\"\n  ) +\n  theme_minimal() +\n  scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) \n})\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 12491 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): Name, Gender, Race, Date, City, State, Manner_of_death, Armed\ndbl (2): UID, Age\nlgl (2): Mental_illness, Flee\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n`summarise()` has grouped output by 'Year'. You can override using the `.groups` argument.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 7 rows containing missing values (`geom_line()`).\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Removed 7 rows containing missing values (`geom_point()`).\n```\n:::\n\n::: {.cell-output-display}\n![](blog-post-3_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "blog-post-3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}